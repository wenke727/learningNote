# Algorithm

- [ ] [Learning to Estimate the Travel Time](https://dl.acm.org/doi/10.1145/3219819.3219900)

## HMM

主要针对低采样率的GPS轨迹提出一种新颖的全局地图匹配算法，称为ST-Matching，其考虑两方面：

1. 道路网络的空间几何和拓扑结构
2. 轨迹的速度/时间约束。基于时空分析，构建候选图，从中确定最佳匹配路径。

observation prob, 观测概率、输出概率，在半径为r rr的范围内搜索该路段的候选集，然后计算候选点，认为均值为0，标准差为20m的一个分布
transmission prob, 转移概率

## 维特比算法

viterbi算法其实就是多步骤每步多选择模型的最优选择问题，其在每一步的所有选择都保存了前续所有步骤到当前步骤当前选择的最小总代价（或者最大价值）以及当前代价的情况下前继步骤的选择。依次计算完所有步骤后，通过回溯的方法找到最优选择路径。符合这个模型的都可以用viterbi算法解决，隐马模型的第三问题刚好符合这个模型，所以才采用了viterbi算法。

Ref：

- [如何通俗地讲解 viterbi 算法？](https://www.zhihu.com/question/20136144)

## 匈牙利算法

匈牙利算法主要用来解决两个问题：求二分图的最大匹配数和最小点覆盖数

Ref:

- [匈牙利算法](https://zhuanlan.zhihu.com/p/96229700)
- [带你入门多目标跟踪（三）匈牙利算法&KM算法](https://zhuanlan.zhihu.com/p/62981901)
- [Lintcode 最佳匹配](https://www.lintcode.com/problem/1576/)

``` python
class Solution:
    def optimalMatch(self, matrix):
        graph, people, bikes = self._format(matrix)

        return self._kuhn_munkres(graph, people, bikes)

    def _kuhn_munkres(self, graph, left_values, right_values):
        n = len(right_values)
        match = [-1] * n

        for left_node in range(n):
            while True:
                left_visited, right_visited = set(), set()
                left_visited.add(left_node)

                if self._hungarian(graph, left_values, right_values, match, left_visited, right_visited, left_node):
                    break
                
                delta = sys.maxsize
                for l in left_visited:
                    for r in range(len(right_values)):
                        if r in right_visited:
                            continue
                        delta = min(delta, left_values[l] + right_values[r] - graph[l][r])
                
                if delta == sys.maxsize:
                    return -1
                
                for l in left_visited:
                    left_values[l] -= delta
                for r in right_visited:
                    right_values[r] += delta
                
        dis = 0
        for r, l in enumerate(match):
            dis += graph[l][r]
        
        return -dis
    
    def _hungarian(self, graph, left_values, right_values, match, left_visited, right_visited, start_node):
        for r in range(len(right_values)):
            if r in right_visited:
                continue
        
            if left_values[start_node] + right_values[r] == graph[start_node][r]:
                right_visited.add(r)
                if match[r] == -1:
                    match[r] = start_node
                    return True
            
                left_visited.add(match[r])
                if self._hungarian(graph, left_values, right_values, match, left_visited, right_visited, match[r]):
                    match[r] = start_node
                    return True

        return False
    
    def _format(self, matrix):
        left_index_set, right_index_set = [], []
        
        for i in range(len(matrix)):
            for j in range(len(matrix[0])):
                if matrix[i][j] == 1:
                    left_index_set.append((i,j))
                if matrix[i][j] == 2:
                    right_index_set.append((i,j))
        
        graph = [[None] * len(right_index_set) for _ in range(len(left_index_set))]
        left_values = [-sys.maxsize] * len(left_index_set)
        right_values = [0] * len(right_index_set)

        for l in range(len(left_index_set)):
            for r in range(len(right_index_set)):
                l_x, l_y = left_index_set[l]
                r_x, r_y = right_index_set[r]
                graph[l][r] = -abs(l_x - r_x) - abs(l_y - r_y)
                left_values[l] = max(left_values[l], graph[l][r])

        return graph, left_values, right_values
```

## Douglas-Peucker(道格拉斯-普克算法)

一种将线段组成的曲线降采样为点数较少的类似曲线的算法。它是最早成功地用于制图综合的算法之一。
给定一条由线段构成的曲线（在某些情况下也称为折线），找到一条点数较少的相似曲线。该算法根据原曲线与简化曲线之间的最大距离（即曲线之间的豪斯多夫距离）来定义 "不相似"。简化曲线由定义原始曲线的点的子集组成。

## 卡尔曼滤波

卡尔曼滤波就是用系统的观测取最优估计系统的状态的方法。这和HMM的解码不太一致，即在模型参数已知的情况下，根据观测序列求最似然状态序列。

本质就是不断利用信息取修正后延分布从而逼近最优分布的过程

数据滤波是去除噪声还原真实数据的一种数据处理技术，Kalman滤波在测量方差已知的情况下能够从一系列存在测量噪声的数据中，估计动态系统的状态。

![pic](https://pic2.zhimg.com/v2-c43b3880ba150ff63101387a6d11d921_r.jpg)

- [图说卡尔曼滤波，一份通俗易懂的教程](https://zhuanlan.zhihu.com/p/39912633)
- [无人驾驶技术入门（十三）| 手把手教你写卡尔曼滤波器](https://zhuanlan.zhihu.com/p/45238681?utm_source=wechat_session&utm_medium=social&utm_oi=689022237218463744&utm_campaign=shareopn)
- [2-D-Kalman-Filter](https://github.com/RahmadSadli/2-D-Kalman-Filter/blob/master/KalmanFilter.py)

``` python
import numpy as np

class KalmanFilter(object):
    '''
    # P、Q、H、R矩阵，任何状态跟踪的问题都将迎刃而解。
    '''
    def __init__(self, init_X, sig, sig_v, dt ):
        x_m, y_m , v_x, v_y = init_X
        self.dt = dt
        self.sig = sig
        self.sig_v = sig_v

        # adding random noise                               (E 1.2)
        self.R = np.matrix([
            [self.sig**2, 0],
            [0, self.sig**2],
        ])
        # noisy measurment of x and y coordinates           (E 1.5)
        self.z = np.matrix([ [x_m], [y_m]] ) 
        # the true, unknown coordinates and velocity        (E 1.6)
        self.X = np.matrix([[x_m], [x_m] , [v_x], [v_y]])
        # measurment mattix translates between x and z      (E 1.8)
        self.H = np.matrix([
            [1,0,0,0],
            [0,1,0,0],
        ])
        # F matrix: linear relationship beween Xi-1 and X   (E 1.10)
        self.F = np.matrix([
            [1, 0, dt, 0 ],
            [0, 1, 0, dt ],
            [0, 0, 1,  0 ],
            [0, 0, 0,  1 ]
        ])
        # zero-mean Gaussian noise                          (E 1.11)
        self.Q = np.matrix([
            [0, 0, 0, 0 ],
            [0, 0, 0, 0 ],
            [0, 0, self.sig_v**2, 0 ],
            [0, 0, 0, self.sig_v**2 ]
        ])
        # estimate of state error covariance                (E 1.12)
        self.P = np.matrix([
            [self.sig**2, 0, 0, 0 ],
            [0, self.sig**2, 0, 0 ],
            [0, 0, self.sig_v**2, 0 ],
            [0, 0, 0, self.sig_v**2 ]
        ])
        self.I = np.eye(self.H.shape[1])

    def set_dt(self, dt):
        self.dt = dt

    def predict(self): 
        self.X = np.dot(self.F, self.X)                     # (E 1.13)
        self.P = self.F*self.P*self.F.T + self.Q            # (E 1.14)

    def update(self, p):
        # measurenment update
        self.z = np.matrix([ p[0], p[1]] ) 
        self.Y = self.z - self.H*self.X                     
        self.S = self.H * self.P * self.H.T + self.R        
        self.K = self.P * self.H.T * np.linalg.inv(self.S)  # (E 1.15)
        self.X = self.X + self.K*self.Y                     # (E 1.16)
        self.P = (self.I - self.K*self.H)*self.P            # (E 1.17)
        return self.X[0,:]
```

## Rtree

思想其实就是先找一个大的空间，再逐步缩小所要查找的空间，最终在一个自己设定的最小不可分空间内找出满足要求的解
R树很好的解决了这种高维空间搜索问题。它把B树的思想很好的扩展到了多维空间，采用了B树分割空间的思想（如果B树在一维的线段进行分割，R树就是在二维甚至多维度的空间），并在添加、删除操作时采用合并、分解结点的方法，保证树的平衡性。因此，R树就是一棵用来存储高维数据的平衡树。

- [空间数据索引RTree（R树）完全解析及Java实现](https://www.cnblogs.com/cmi-sh-love/p/kong-jian-shud-ju-suo-yinRTree-wan-quan-jie-xi-jiJa.html)

## 轨迹相似度

- [衡量轨迹相似度算法](https://chuxiuhong.com/post/trajectory-distance/#%E5%B8%A6%E6%83%A9%E7%BD%9A%E7%9A%84%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BBedit-distance-with-real-penalty)

### Dynamic Time Warping Distance

DTW（动态时间规整算法）是一种非常有用的计算序列最小距离的方法, 不论是在语音序列匹配, 股市交易曲线匹配, 还是DNA碱基序列匹配等等场景, 都有其大展身手的地方. 它的最大特点是在匹配时允许时间上的伸缩, 因此可以更好的在一堆序列集合中找到最佳匹配的序列.

The basic idea of DTW is to allow ‘repeating’ some points as many times as needed in order to get the best alignment.

- [理解dynamic time warping(DTW)的基本思想](https://zhuanlan.zhihu.com/p/117634492)

```python
# DTW计算序列s1,s2的最小距离
def DTW(s1,s2):
    m = len(s1)
    n = len(s2)

    # 构建二位dp矩阵,存储对应每个子问题的最小距离
    dp = [[0]*n for _ in range(m)] 

    # 起始条件,计算单个字符与一个序列的距离
    for i in range(m):
        dp[i][0] = distance(s1[i],s2[0])
    for j in range(n):
        dp[0][j] = distance(s1[0],s2[j])
    
    # 利用递推公式,计算每个子问题的最小距离,矩阵最右下角的元素即位最终两个序列的最小值
    for i in range(1,m):
        for j in range(1,n):
            dp[i][j] = min(dp[i-1][j-1],dp[i-1][j],dp[i][j-1]) + distance(s1[i],s2[j])
    
    return dp[-1][-1]

s1 = [1,3,2,4,2]
s2 = [0,3,4,2,2]

print('DTW distance: ',DTW(s1,s2))   # 输出 DTW distance:  2
```

### Longest Common Subsequence

- [时间序列表示学习](https://zhuanlan.zhihu.com/p/55306421)

